<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://zhonglinxie.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://zhonglinxie.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-04-10T11:08:07+00:00</updated><id>https://zhonglinxie.github.io/feed.xml</id><title type="html">blank</title><entry><title type="html">The copyright information is moved to this post</title><link href="https://zhonglinxie.github.io/blog/2024/remove-footer/" rel="alternate" type="text/html" title="The copyright information is moved to this post"/><published>2024-05-28T00:00:00+00:00</published><updated>2024-05-28T00:00:00+00:00</updated><id>https://zhonglinxie.github.io/blog/2024/remove-footer</id><content type="html" xml:base="https://zhonglinxie.github.io/blog/2024/remove-footer/"><![CDATA[<p>The footer information originally included in this website’s theme has been removed and may now be found within this blog post. This modification is permitted under the terms of the MIT License, which grants users the right to “use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software.” I moved the footer information for simplicity, which contains the copyright notice:</p> <blockquote> <p>Powered by <a href="https://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.</p> </blockquote> <p>Reference: <a href="https://opensource.stackexchange.com/questions/1786/removing-the-original-copyright-line-from-footer?rq=1">StackExchange question</a>.</p>]]></content><author><name></name></author><category term="comments"/><summary type="html"><![CDATA[The footer information originally included in this website’s theme has been removed and may now be found within this blog post. This modification is permitted under the terms of the MIT License, which grants users the right to “use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software.” I moved the footer information for simplicity, which contains the copyright notice:]]></summary></entry><entry><title type="html">Plug-and-Play: Algorithms, Parameters Tuning and Interpretation</title><link href="https://zhonglinxie.github.io/blog/2022/Plug-and-Play/" rel="alternate" type="text/html" title="Plug-and-Play: Algorithms, Parameters Tuning and Interpretation"/><published>2022-03-01T00:00:00+00:00</published><updated>2022-03-01T00:00:00+00:00</updated><id>https://zhonglinxie.github.io/blog/2022/Plug%20and%20Play</id><content type="html" xml:base="https://zhonglinxie.github.io/blog/2022/Plug-and-Play/"><![CDATA[<p>本文为北京大学最优化讨论班 2022 年 3 月 1 日的讲稿<d-footnote>在知乎同步更新</d-footnote>, 综合了</p> <ul> <li><a href="https://ieeexplore.ieee.org/document/8962388?arnumber=8962388">https://ieeexplore.ieee.org/document/8962388?arnumber=8962388</a><d-cite key="ieee_8962388"></d-cite> (IEEE Signal Processing Magzine)</li> <li><a href="https://proceedings.mlr.press/v119/wei20b">https://proceedings.mlr.press/v119/wei20b</a><d-cite key="pmlr-v119-wei20b"></d-cite> (ICML 2020 Award Paper)</li> <li><a href="https://jmlr.org/papers/v23/20-1297.html">https://jmlr.org/papers/v23/20-1297.html</a><d-cite key="jmlr-23-16-2022"></d-cite> (JMLR)</li> <li><a href="https://epubs.siam.org/doi/abs/10.1137/20M1337168">https://epubs.siam.org/doi/abs/10.1137/20M1337168</a><d-cite key="siam_20M1337168"></d-cite> (SIAM Journal on Imaging Sciences)</li> <li><a href="https://epubs.siam.org/doi/10.1137/16M1102884">https://epubs.siam.org/doi/10.1137/16M1102884</a><d-cite key="siam_16M1102884"></d-cite> (SIAM Journal on Imaging Sciences)</li> </ul> <p>等几篇文章的主要内容, 着重介绍它们在理论上的进展及各方法提供的 insights.</p> <h2 id="maximum-a-posteriori-probability-map-estimate">maximum a posteriori probability (MAP) estimate</h2> <p>考虑如下的线性反问题:</p> \[y=Ax+\varepsilon.\] <p>给定带有噪音 \(\varepsilon\) 的观测值 \(y\), 我们需要从中恢复出原始信号 \(x\). 这一类问题广泛出现在图像处理领域. 在贝叶斯统计中, 常将这类问题建模为最大化后验概率 (Maximum A Posteriori) 估计. 根据贝叶斯公式, 观测值为 \(y\) 时原信号为 \(x\) 的后验概率满足</p> \[\mathbb{P}(x\mid y)=\frac{\mathbb{P}(y\mid x)\mathbb{P}(x)}{\mathbb{P}(y)}.\] <p>最大化后验概率估计试图从所有可能的 \(x\) 中选出使得后验概率 \(\mathbb{P}(x\mid y)\) 最大的那个. 注意到, 上式的分母仅被 \(y\) 决定, 最大化 \(\mathbb{P}(x\mid y)\) 等价与最大化分子 \(\mathbb{P}(y\mid x)\mathbb{P}(x)\). 涉及两函数之积的优化往往较为复杂, 而概率的特性决定了 \(\mathbb{P}(y\mid x)&gt;0\) 与 \(\mathbb{P}(x)&gt;0\) 在大多数情形下成立. 因此, 我们可以引入对数, 将乘积转换为求和, 此时最大化后验概率估计等价于</p> \[\min_{x}\, -\ln\mathbb{P}(y\mid x) - \ln\mathbb{P}(x).\] <p>在实践中, 加性白高斯噪声 (Additive White Gaussian Noise) 是一种被广泛采用的假设. 在这一假设下, 噪声 \(\varepsilon\sim \mathcal{N}(0,\sigma^2I)\), 其中 \(\mathcal{N}(0,\sigma^2I)\) 是均值为 \(0\), 协方差矩阵为 \(\sigma^2I\) 的多元高斯分布. 于是</p> \[\mathbb{P}(y\mid x)=\mathbb{P}(\varepsilon=y-Ax)=\frac{1}{(2\pi\sigma^2)^{n/2}}\exp\left(-\frac{\Vert Ax-y\Vert ^2}{2\sigma^2}\right).\] <p>忽略常数后, 最大化后验概率在加性白高斯噪声的假设下等价于</p> \[\min_{x}\, \frac{1}{2\sigma^2} \Vert Ax-y\Vert ^2 - \ln\mathbb{P}(x).\] <p>此时, 只要选定先验概率 \(\mathbb{P}(x)\) 即可给出优化模型. 我们将 \(- \ln\mathbb{P}(x)\) 记为 \(\varphi(x)\), 则 \(\varphi(x)\) 应当尽可能与某个函数的负对数相等, 同时使得上述优化问题易于处理. 一种常见的选择是 \(\varphi(x)=\lambda\Vert \Psi x\Vert _1\), 且 \(\Psi^\top\Psi=I\), \(\lambda&gt;0\). 这样的 \(\varphi(x)\) 在保证优化问题凸性的同时使得输出 \(\Psi x\) 较为稀疏. \(\varphi(x)\) 常被称作正则项, 它向模型中添加了某种先验信息, 有大量的工作致力于选取合适的 \(\varphi(x)\).</p> <h2 id="去噪问题">去噪问题</h2> <p>当线性反问题中的 \(A\) 是单位矩阵 \(I\) 时, 观测值与原信号满足 \(y=x+\varepsilon\). 这种特殊的线性反问题被称为去噪, 在去噪问题上表现最好的工作都是基于物理直觉设计算法或运用神经网络. 我们能否借助去噪问题的算法来处理一般的线性反问题呢? 答案是肯定的, 这正是 Plug-and-Play 的做法.</p> <h2 id="admm">ADMM</h2> <p>在正式介绍 Plug-and-Play 前, 我们先来看如何处理最大化后验概率估计:</p> \[\min_{x}\, \frac{1}{2\sigma^2} \Vert Ax-y\Vert ^2 + \varphi(x).\] <p>直接针对 \(x\) 进行优化往往困难重重, 我们可以引入辅助变量 \(v\), 将上述问题等价转化为约束优化问题</p> \[\min_{x}\, \frac{1}{2\sigma^2} \Vert Ax-y\Vert ^2 + \varphi(v), \quad \text{ s.t. } x=v.\] <p>Alternating Direction Method of Multipliers (ADMM) 非常适合用来求解这种变量分块的问题. 引入乘子 \(z\) 与罚因子 \(1/\eta\), 其增广拉格朗日函数为</p> \[\begin{aligned} L(x,v;u)&amp;=\frac{1}{2\sigma^2} \Vert Ax-y\Vert ^2 + \varphi(v)-z^\top(x-v) + \frac{1}{2\eta}\Vert x-v\Vert ^2\\ &amp;=\frac{1}{2\sigma^2} \Vert Ax-y\Vert ^2 + \varphi(v) + \frac{1}{2\eta}\Vert x-v-u\Vert ^2-\frac{1}{2\eta}\Vert u\Vert ^2.\quad(u=\eta z) \end{aligned}\] <p>于是 ADMM 所给出的迭代为</p> \[\left\{ \begin{aligned} x^{k+1}&amp;=\underset{x}{\arg\min}\, L(x,v^k;u^k)=(A^\top A+\frac{\sigma^2}{\eta}I)^{-1}\left(A^\top y+\frac{\sigma^2}{\eta}(v^k-u^k)\right),\\ v^{k+1}&amp;=\underset{v}{\arg\min}\, L(x^{k+1},v;u^k)=\operatorname{prox}_{\eta\varphi(\cdot)}(x^{k+1}-u^k),\\ u^{k+1}&amp;=u^k-(x^{k+1}-v^{k+1}). \end{aligned}\right.\] <h2 id="pnp-admm">PnP-ADMM</h2> <p>注意到 proximal 算子</p> \[\begin{aligned} \operatorname{prox}_{\eta\varphi(\cdot)}(x^{k+1}-u^k) &amp;= \underset{v}{\arg\min}\, \eta\varphi(v)+\frac{1}{2}\Vert v-x^{k+1}+u^k\Vert ^2\\ &amp;=\underset{v}{\arg\min}\, \varphi(v)+\frac{1}{2\eta}\Vert v-x^{k+1}+u^k\Vert ^2 \end{aligned}\] <p>可以被视为观测值为 \(x^{k+1}-u^k\), 正则项为 \(\varphi(v)\), 噪声服从 \(\mathcal{N}(0,\eta I)\) 的<strong>去噪问题所对应的最大化后验概率估计</strong>! 基于这种形式上的相似性, 我们考虑用现有的去噪算法替代 ADMM 中对 \(v\)-子问题的优化. 将去噪算法抽象为 \(f(\cdot,\eta)\), 保留 \(\eta\) 是因为去噪算法中常常需要指定噪声的大小. 于是 PnP-ADMM 写作</p> \[\left\{ \begin{aligned} x^{k+1}&amp;=(A^\top A+\frac{\sigma^2}{\eta}I)^{-1}\left(A^\top y+\frac{\sigma^2}{\eta}(v^k-u^k)\right),\\ v^{k+1}&amp;=f(x^{k+1}-u^k,\eta),\\ u^{k+1}&amp;=u^k-(x^{k+1}-v^{k+1}). \end{aligned}\right.\] <p>令人惊喜的是, 这样一种简单的替换就可以带来巨大的提升. <img src="/assets/img/PnP-notes/v2-58978ddaaf9b9ac596e15af6453c46c3_b.jpg" alt=""/></p> <p>前缀 CS 是 Compress Sensing 的缩写, 是一种传统方法, 纵坐标 NMSE 全称 Normalized Mean-Squared Error, 度量了算法所恢复出的信号与真实的原始信号的差距, UWT 是 undecimated wavelet transform 的缩写. TV 表示 Total Variation, CNN 则表示用基于卷积神经网络的去噪算法替换 v-迭代所得到的 PnP 算法. 可以看出, 基于 PnP 的方法在收敛速度与解的质量上都优于传统算法.</p> <h2 id="参数的选择">参数的选择</h2> <p>细心的同学可能已经注意到了在 PnP-ADMM 中, 参数 \(\eta\) 的取值是固定的. 正如传统的 ADMM 算法中, 罚因子的选择会影响算法的效果, 在 PnP-ADMM, 不同的 \(\eta\) 表现也大不相同. <img src="/assets/img/PnP-notes/v2-995a980309e0c64d8f3108555dc81c98_b.jpg" alt=""/></p> <p>纵坐标为 PSNR (Peak Signal-to-Noise Ratio) 峰值信噪比, 其度量了图像恢复的质量, 不同颜色表示 eta 取不同值时 PSNR 随迭代次数变化的曲线.</p> <p>PSNR计算方法为 (参考 <a href="https://zhuanlan.zhihu.com/p/50757421">https://zhuanlan.zhihu.com/p/50757421</a>):</p> <blockquote> <p>给定一个大小为 \(m \times n\) 的干净图像 \(I\) 和噪声图像 \(K\), 均方误差 (MSE) 定义为:</p> \[\text{MSE}=\frac{1}{m n} \sum_{i=0}^{m-1} \sum_{j=0}^{n-1}[I(i, j)-K(i, j)]^{2}\] <p>PSNR(dB) 定义为：</p> \[\text{PSNR}=10\log _{10}\left(\frac{\text{MAX}_{I}^{2}}{\text{MSE}}\right)\] <p>其中 \(\text{MAX}_{I}^{2}\) 为图片可能的最大像素值. 如果每个像素都由 8 位二进制来表示, 那么就为 255. 如果像素值由 B 位二进制来表示, 那么 \(\text{MAX}_{I}=2^{B}-1\).</p> </blockquote> <p>这说明噪声水平的选择对 PnP-ADMM 的影响同样巨大, 针对不同的图片, 最优的噪声水平也是不同的. 受此启发, 我们联想到在 ADMM 中常根据原始残差与对偶残差的相对大小来动态调整罚因子, 以加速收敛. 因此, 我们可以将 PnP-ADMM 中的 \(\eta\) 与 \(\sigma^2/\eta\) 变为随步数动态调整的参数 \(\eta_k\), \(\mu_k\). 但问题在于 PnP-ADMM 并不是从某个优化问题基于 ADMM 导出的迭代格式, ADMM 中的理论可能失效, 此时该如何选取动态的步长 \(\eta_k\), \(\mu_k\) 呢?</p> <h2 id="markov-decision-process">Markov Decision Process</h2> <p>实际上, 若从更加抽象的角度来考察迭代算法, 它们都可以被看作一种特殊的马尔可夫决策过程. 具体而言, 我们将 \(x^k\), \(v^k\), \(u^k\) 视为 Agent 在时刻 \(k\) 的状态 (State) \(s_k\). 将两个参数 \(\eta_k\), \(\mu_k\) 看作 Agent 在时刻 \(k\) 采取的动作 (Action), 同时 Agent 还需决定是否终止迭代, 这可以通过一个二元变量 \(\tau_k\) 来表达, 将这些随 \(k\) 变化的参数记为 \(a_k\). 那么其 \(k+1\) 的状态 \(s_{k+1}\) 就被 \(s_k\) 与 \(a_k\) 决定, 用 MDP 的术语来说, \(s_{t+1}=p(s_t,a_t)\), 其中 \(p(s_t,a_t)\) 是概率转移函数, 在这种设定下等价于策略 (Policy). 最后, 我们基于 PnP-ADMM 希望在尽可能少的步数内提升信号恢复质量的目标定义奖励函数 (Reward)</p> \[r\left(s_{t}, a_{t}\right)=\left[\zeta\left(p\left(s_{t}, a_{t}\right)\right)-\zeta\left(s_{t}\right)\right]-\eta.\] <p>其中 \(\zeta(s_t)\) 是第 \(t\) 步恢复出的信号的 PSNR 值, 而 \(\eta\) 则是一个常数, 用来惩罚 PnP-ADMM 在第 \(t\) 步仍未结束迭代.</p> <p>将以上论述归纳为标准的 MDP, 则得到四元组 \((\mathcal{S}, \mathcal{A}, p, r)\).</p> <ul> <li>\(\mathcal{S}\): 状态空间, 任何可行的 \(x^k\), \(v^k\), \(u^k\) 三元组.</li> <li>\(\mathcal{A}\): 动作空间, 任何可行的 \(\eta_k\), \(\mu_k\) 二元组与 \(\tau_k\in\{0,1\}.\)</li> <li>\(p\): 概率转移函数, PnP-ADMM 在给定 \(a_t\), \(s_t\) 后的一步迭代.</li> <li>\(r\): 奖励函数, \(r\left(s_{t}, a_{t}\right)=\left[\zeta\left(p\left(s_{t}, a_{t}\right)\right)-\zeta\left(s_{t}\right)\right]-\eta.\)</li> </ul> <p><img src="/assets/img/PnP-notes/v2-ac731dd6f190f332d9958ca3a272423a_b.jpg" alt=""/></p> <p>将 PnP-ADMM 建模为强化学习的示意图.</p> <p>有了这种建模, 剩下的工作就是精确刻画其训练过程. 给定轨迹 (Trajectory)</p> \[T=\left\{s_{0}, a_{0}, r_{0}, \cdots, s_{N}, a_{N}, r_{N}\right\}\] <p>与折现因子 (Factor) \(\rho\), 在时刻 \(t\) 的回报 (Return) 定义为</p> \[R_{t}=\sum_{t^{\prime}=0}^{N-t} \rho^{t^{\prime}} r\left(s_{t+t^{\prime}}, a_{t+t^{\prime}}\right).\] <p>而我们的目标则是得到一个策略 \(\pi\), 使得由该策略导出的轨迹在初始时刻回报的期望值最大</p> \[J(\pi)=\mathbb{E}_{s_{0}, \pi}\left[R_{0}\right],\quad \pi(a \mid s): \mathcal{S}\times \mathcal{A} \rightarrow [0,1].\] <p>其状态值函数 (State-value function) 定义为</p> \[V^{\pi}(s)=\mathbb{E}_{\pi}\left[R_{0} \mid s_{0}=s\right].\] <p>动作值函数 (Action-value function) 定义为</p> \[Q^{\pi}(s, a)=\mathbb{E}_{\pi}\left[R_{0} \mid s_{0}=s, a_{0}=a\right].\] <p>而策略 \(\pi\) 则由两个子策略 \(\pi_1\), \(\pi_2\) 组成. 其中 \(\pi_1\) 是一个随机的策略, 以一定概率输出 \(0\), \(1\), 若输出为 \(1\) 则继续迭代, 否则终止迭代. 而 \(\pi_2\) 是一个确定性策略, 它本质上由 PnP-ADMM 的几步迭代组成, 是一个输出为连续空间的确定性策略.</p> <h3 id="actor-critic-framework">Actor-critic Framework</h3> <p>策略的训练用到了著名的 Actor-critic Framework. 首先定义策略网络 (actor): \(\pi_\theta=(\pi_1,\pi_2)\), 其中 \(\theta = (\theta_1,\theta_2)\).</p> <ul> <li>\(\pi_1(\cdot\mid s)\): \(\mathcal{S}\times \{0,1\}\to [0,1]\), 由 \(\theta_1\) 控制.</li> <li>\(\pi_2(s)\): \(\mathcal{S}\to \mathcal{A}\), 由 \(\theta_2\) 控制.</li> </ul> <p>再定义价值网络 (critic): \(V_{\phi}^{\pi}\left(s_{t}\right)\), 其中 \(\phi\) 是该网络的参数.</p> <p>价值网络的训练目标是使其尽可能满足贝尔曼方程 (Bellman equation), 损失函数为</p> \[L_{\phi}=\mathbb{E}_{s \sim B, a \sim \pi_{\theta}(s)}\left[\frac{1}{2}\left(r(s, a)+\gamma V_{\hat{\phi}}^{\pi}(p(s, a))-V_{\phi}^{\pi}(s)\right)^{2}\right].\] <p>\(\pi_1\) 与 \(\pi_2\) 的训练则使用了策略梯度法 (Policy Gradient). 采用免模型 (Model-free) 的方法来训练 \(\pi_1\), 其梯度为</p> \[\nabla_{\theta_{1}} J\left(\pi_{\theta}\right)=\mathbb{E}_{s \sim B, a \sim \pi_{\theta}(s)}\left[\nabla_{\theta_{1}} \log \pi_{1}\left(a_{1} \mid s\right) A^{\pi}(s, a)\right].\] <p>而 \(\pi_2\) 的训练则是基于模型的, 其梯度为</p> \[\nabla_{\theta_{2}} J\left(\pi_{\theta}\right)=\mathbb{E}_{s \sim B, a \sim \pi_{\theta}(s)}\left[\nabla_{a_{2}} Q^{\pi}(s, a) \nabla_{\theta_{2}} \pi_{2}(s)\right].\] <p>整个训练过程的伪代码摘录如下, 由于这部分并非我们关注的重点, 故较为简略, 请感兴趣的读者参阅原论文: <a href="https://jmlr.org/papers/v23/20-1297.html">https://jmlr.org/papers/v23/20-1297.html</a>. <img src="/assets/img/PnP-notes/v2-b86d9ec78fc50fd397c5f430233e1d1f_b.jpg" alt=""/></p> <p>训练过程的伪代码.</p> <p>数值试验的结果表明, 通过强化学习得到的参数在恢复效果与迭代次数上都优于其他方法 (见下图中的 Ours 栏目, PSNR 的计算方法上文已给出, \(\#\mathrm{IT}.\) 表示迭代次数). <img src="/assets/img/PnP-notes/v2-2004b96a934cd2606eee46fb27beaa7c_b.jpg" alt=""/></p> <p>不同方法的恢复效果.</p> <p><img src="/assets/img/PnP-notes/v2-d825dd8c176a296d30a4956bfdf89236_b.jpg" alt=""/></p> <p>不同方法恢复效果与迭代次数的对比, IT 表示迭代次数.</p> <h2 id="对-pnp-admm-的再思考">对 PnP-ADMM 的再思考</h2> <p>在上文的推导中, 我们根据形式的相似性想到用去噪算法 \(f\) 替代 ADMM 中的 \(v\)-迭代, 但 \(f\) 很可能不是任何正则项 \(\varphi(\cdot)\) 所对应的 proximal 算子. 只有当</p> \[p({x})\propto \exp(-\varphi({x})),\quad {z}-{z}_{\mathrm{true}}\sim\mathcal{N}({0},\eta{I})\] <p>时, \(f\) 才与 \(\operatorname{prox}_{\eta\varphi(\cdot)}({z})\) 一致. 然而 \(f\) 很可能不正比于 \(\exp(-\varphi({x}))\), 而</p> \[\left({x}_{k}+{u}_{k-1}\right)-\left({x}_{k}+{u}_{k-1}\right)_{\mathrm{true}}\] <p>的分布也未知! 因此 PnP 只是根据形式上的相似性导出的结果. 那么能否从理论上去解释它呢? 既然 PnP-ADMM 并非某一优化问题所对应的 ADMM 算法, 那么它收敛吗? 如果收敛, 又收敛于什么值?</p> <h2 id="regularization-by-denoiser-red">Regularization by Denoiser (RED)</h2> <p>为了回答上述问题, 我们先介绍 Regularization by Denoiser (RED) 方法, 这一方法在选择了适当的去噪算子与超参数后可以达到 SOTA 的表现, 同时, 基于这一方法可以给出 PnP-ADMM 的收敛性. RED 即利用去噪算子做正则项, 我们定义</p> \[\rho_{\operatorname{RED}}({x})\triangleq \frac{1}{2}\langle{x}, {x}-{f}({x})\rangle, \quad\ell({x} ; {y})=\frac{1}{2 \sigma^{2}}\Vert {y}-{A} {x}\Vert _2^2.\] <p>则其所对应的 MAP 问题为</p> \[\widehat{\boldsymbol{x}}_{\mathrm{RED}}=\underset{\boldsymbol{x}\in \mathbb{R}^{n}}{\arg\min}\; \ell(\boldsymbol{x} ; \boldsymbol{y})+\rho_{\operatorname{RED}}(\boldsymbol{x}).\] <p>神奇的是, 当 \(f\) 具有如下四个性质时</p> <blockquote> <p>Local Homogeneity:</p> \[\boldsymbol{f}((1+\varepsilon) \boldsymbol{x})=(1+\varepsilon) \boldsymbol{f}(\boldsymbol{x}),\quad\forall \boldsymbol{x} \in \mathbb{R}^{n}, 0 &lt; \varepsilon \ll 1.\] <p>\(\boldsymbol{f}(\cdot)\) is differentiable where \(J \boldsymbol{f}\in \mathbb{R}^{n\times n}\) denotes its Jacobian.</p> <p><strong>Jacobian Symmetry</strong>: \(J \boldsymbol{f}(\boldsymbol{x})^\intercal=J \boldsymbol{f}(\boldsymbol{x}), \forall \boldsymbol{x} \in \mathbb{R}^{n}\).</p> <p>The spectral radius the Jacobian satisfies \(\eta(J \boldsymbol{f}(\boldsymbol{x})) \leq 1\).</p> </blockquote> <p>其最优化条件恰好为</p> \[{0}=\frac{1}{\sigma^{2}} {A}^{\intercal}({A} \widehat-{y})+\frac{1}{\eta}(\widehat-{f}(\widehat)).\] <p>其证明如下 (开摆, 直接贴 slides 了)</p> <div style="text-align: center;"> <img src="/assets/img/PnP-notes/v2-8f69e3bbb6efcd49437b7d765015da88_b.jpg" alt="Example Image" style="max-width: 100%; height: auto;"/> </div> <p>RED 最优性条件的推导</p> <p><img src="/assets/img/PnP-notes/v2-0ddddcf9b684344934062ce819c8c491_b.jpg" alt=""/></p> <p>RED 的注记</p> <p>那么这里介绍的 RED 和之前介绍的 PnP 有什么区别呢? 我们用一个 toy example 来进行说明. 考虑 \(\boldsymbol{f}(\boldsymbol{z})=\boldsymbol{W} \boldsymbol{z}\), 其中 \(\boldsymbol{W}=\boldsymbol{W}^{\top}\). \(\boldsymbol{f}\) 是 \(\varphi(\boldsymbol{x})=(1 / 2 \eta) \boldsymbol{x}^{\top}\left(\boldsymbol{W}^{-1}-\boldsymbol{I}\right) \boldsymbol{x}\) 所对应的 proximal 算子.</p> <p>PnP 面临的优化问题为</p> \[\widehat{\boldsymbol{x}}_{\mathrm{pnp}}=\underset{\boldsymbol{x}}{\operatorname{argmin}}\left\{\frac{1}{2 \sigma^{2}}\Vert \boldsymbol{y}-\boldsymbol{A} \boldsymbol{x}\Vert ^{2}+\frac{1}{2 \eta} \boldsymbol{x}^{\top}\left(\boldsymbol{W}^{-1}-\boldsymbol{I}\right) \boldsymbol{x}\right\}.\] <p>而 RED 则试图求解</p> \[\widehat{\boldsymbol{x}}_{\mathrm{red}}=\underset{\boldsymbol{x}}{\operatorname{argmin}}\left\{\frac{1}{2 \sigma^{2}}\Vert \boldsymbol{y}-\boldsymbol{A x}\Vert ^{2}+\frac{1}{2 \eta} \boldsymbol{x}^{\top}(\boldsymbol{I}-\boldsymbol{W}) \boldsymbol{x}\right\}.\] <p>可以看出, 它们的区别在于正则项中对误差的 scale 不同, PnP 与 RED 相比正好差了一个 \(W\).</p> <h2 id="如何理解-red-score-matching">如何理解 RED: Score Matching</h2> <p>给定训练集 \(\{\boldsymbol{x}_t\}_{t=1}^{T}\), empirical prior model 定义为</p> \[\widehat{p}(\boldsymbol{x}) \triangleq \frac{1}{T} \sum_{t=1}^{T} \delta\left(\boldsymbol{x}-\boldsymbol{x}_{t}\right),\] <p>其中 \(\delta\) 是狄拉克函数. 将狄拉克函数 \(\delta\left(\boldsymbol{x}-\boldsymbol{x}_{t}\right)\) 用协方差矩阵为 \(\eta I\) 均值为 \(x_t\) 的高斯分布 \(\mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{x}_{t}, \eta \boldsymbol{I}\right)\) 替换则得到 kernel density estimation (KDE):</p> \[\tilde{p}(\boldsymbol{x} ; \eta) \triangleq \frac{1}{T} \sum_{t=1}^{T} \mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{x}_{t}, \eta \boldsymbol{I}\right).\] <p>将 \(\tilde{p}\) 视为 MAP 中对 \(x\) 的先验估计, 则 MAP 问题变为</p> \[\widehat{\boldsymbol{x}}=\underset{\boldsymbol{x}}{\operatorname{argmin}}\;\frac{1}{2 \sigma^{2}}\Vert \boldsymbol{y}-\boldsymbol{A x}\Vert ^{2}-\ln \tilde{p}(\boldsymbol{x} ; \eta).\] <p>其最优化条件为</p> \[\mathbf{0}=\frac{1}{\sigma^{2}} \boldsymbol{A}^{\top}(\boldsymbol{A} \widehat{\boldsymbol{x}}-\boldsymbol{y})-\nabla \ln \tilde{p}(\widehat{\boldsymbol{x}} ; \eta)\] <p>若将去噪算子选为最小均方误差 \(\boldsymbol{f}_{\mathrm{mmse}}(\boldsymbol{z};\eta)=\mathbb{E}[\boldsymbol{x}\mid\boldsymbol{z}]\), 其中 \(\boldsymbol{z}=\boldsymbol{x}+\mathcal{N}(\mathbf{0}, \eta \boldsymbol{I}), \boldsymbol{x} \sim \widehat{p}\). 则利用 Tweedie’s formula 可以得到</p> \[\nabla \ln \tilde{p}(\boldsymbol{z} ; \eta)=\frac{1}{\eta}\left(\boldsymbol{f}_{\mathrm{mmse}}(\boldsymbol{z} ; \eta)-\boldsymbol{z}\right).\] <p>而上式恰好是 RED 在 \(f\) 为最小均方误差 \(\boldsymbol{f}_{\mathrm{mmse}}(\boldsymbol{z};\eta)=\mathbb{E}[\boldsymbol{x}\mid\boldsymbol{z}]\) 时的最优性条件, 这就从建模的角度给出 RED 的直觉. 但如果 \(f\) 不等于 \(\boldsymbol{f}_{\mathrm{mmse}}\) 呢, 此时又该如何理解 RED? 我们考虑一个由神经网络给出的去噪算子 \(f_\theta\), 其中 \(\theta\) 是参数, 训练策略为</p> \[\min_{\theta}\;\mathbb{E}\Vert \boldsymbol{x}-\boldsymbol{f}_{\theta}(\boldsymbol{z})\Vert ^2,\quad\text{where}\quad \boldsymbol{x}\sim \widehat{p},\quad \boldsymbol{z}=\boldsymbol{x}+\mathcal{N}(\mathbf{0}, \eta \boldsymbol{I}).\] <p>利用最小均方误差 (MMSE) 所具备的正交性质 (类似于欧氏空间中的正交分解), 损失函数又可以分解为</p> \[\mathbb{E}\left\Vert \boldsymbol{x}-\boldsymbol{f}_{\boldsymbol{\theta}}(\boldsymbol{z})\right\Vert ^{2}= \mathbb{E}\left\Vert \boldsymbol{x}-\boldsymbol{f}_{\mathrm{mmse}}(z ; \eta)\right\Vert ^{2} +\mathbb{E}\left\Vert \boldsymbol{f}_{\mathrm{mmse}}(\boldsymbol{z} ; \eta)-\boldsymbol{f}_{\boldsymbol{\theta}}(\boldsymbol{z})\right\Vert ^{2}.\] <p>再次使用 Tweedie’s formula, 我们得到</p> \[\begin{aligned} \widehat{\boldsymbol{\theta}} &amp;=\underset{\boldsymbol{\theta}}{\operatorname{argmin}}\;\mathbb{E}\Vert \boldsymbol{x}-\boldsymbol{f}_{\theta}(\boldsymbol{z})\Vert ^2\\ &amp;=\underset{\boldsymbol{\theta}}{\operatorname{argmin}}\; \mathbb{E}\left\Vert \boldsymbol{f}_{\mathrm{mmse}}(z ; \eta)-\boldsymbol{f}_{\boldsymbol{\theta}}(z)\right\Vert ^{2} \\ &amp;=\underset{\boldsymbol{\theta}}{\operatorname{argmin}}\; \mathbb{E}\Vert \nabla \ln \tilde{p}(z ; \eta)-\frac{1}{\eta}\left(f_{\boldsymbol{\theta}}(z)-z\right)\Vert ^{2}. \end{aligned}\] <p>也就是说, 在去噪算子不是 \(\boldsymbol{f}_{\mathrm{mmse}}\) 时, 我们会首先选择 \(\boldsymbol{\theta}\) 使得 \((f_{\theta}(z)-z)/\eta\) 与 ``score’’ \(\nabla \ln \tilde{p}\) 吻合得最好, 再将至运用于 RED 中.</p> <h2 id="pnp-与-red-的一致均衡框架-consensus-equilibrium">PnP 与 RED 的一致均衡框架 (Consensus Equilibrium)</h2> <p>为了证明 PnP 的收敛性, 我们直接考虑其迭代格式, 实际上, PnP 可以被视为迭代求解下列不动点方程:</p> \[\begin{aligned} &amp;\widehat{\boldsymbol{x}}_{\mathrm{pnp}}=\boldsymbol{h}\left(\widehat{\boldsymbol{x}}_{\mathrm{pnp}}-\widehat{\boldsymbol{u}}_{\mathrm{pnp}} ; \eta\right), \\ &amp;\widehat{\boldsymbol{x}}_{\mathrm{pnp}}=\boldsymbol{f}\left(\widehat{\boldsymbol{x}}_{\mathrm{pnp}}+\widehat{\boldsymbol{u}}_{\mathrm{pnp}}\right). \end{aligned}\] <p>其中</p> \[\begin{aligned} \boldsymbol{h}(\boldsymbol{z} ; \eta) &amp; \triangleq \underset{\boldsymbol{x}\in \mathbb{R}^{n}}{\arg\min}\;\frac{1}{2 \sigma^{2}}\Vert \boldsymbol{y}-\boldsymbol{A} \boldsymbol{x}\Vert ^{2}+\frac{1}{2 \eta}\Vert \boldsymbol{x}-\boldsymbol{z}\Vert ^{2} \\ &amp;=\left(\boldsymbol{A}^{\intercal} \boldsymbol{A}+\frac{\sigma^{2}}{\eta} \boldsymbol{I}\right)^{-1}\left(\boldsymbol{A}^{\intercal} \boldsymbol{y}+\frac{\sigma^{2}}{\eta} \boldsymbol{z}\right) . \end{aligned}\] <p>这个不动点方程可以进一步抽象为</p> \[\begin{aligned} &amp;\underline{z}=(2 \boldsymbol{G}-\boldsymbol{I})(2 \mathcal{F}-\boldsymbol{I}) \underline{z}, \\ &amp;\underline{z}=\left[\begin{array}{l} z_{1} \\ z_{2} \end{array}\right], \quad \mathcal{F}(\underline{z})=\left[\begin{array}{c} \boldsymbol{h}\left(z_{1} ; \eta\right) \\ \boldsymbol{f}\left(z_{2}\right) \end{array}\right], \quad\mathcal{G}(\underline{z})=\left[\begin{array}{c} \left(z_{1}+z_{2}\right)/2 \\ \left(z_{1}+z_{2}\right)/2 \end{array}\right]. \end{aligned}\] <p>求解这一方程的 Mann 迭代格式 (类似于 Anderson 加速) 为</p> \[\underline{\boldsymbol{z}}^{(k+1)}=(1-\gamma) \underline{\boldsymbol{z}}^{k}+\gamma(2 \boldsymbol{G}-\boldsymbol{I})(2 \mathcal{F}-\boldsymbol{I}) \underline{\boldsymbol{z}}^{(k)}.\] <p>这就从 Mann 迭代的收敛性即可保证 PnP 的收敛性.</p> <p>同理, 对于 RED, 若采用 ADMM 求解 (推导与 MAP 的 ADMM 类似, 故省略), 则其迭代写为</p> \[\begin{aligned} &amp;\widehat{\boldsymbol{x}}_{\mathrm{red}}=\boldsymbol{h}\left(\widehat{\boldsymbol{x}}_{\mathrm{red}}-\widehat{\boldsymbol{u}}_\mathrm{red} ; \eta\right) \\ &amp;\widehat{\boldsymbol{x}}_{\mathrm{red}}=\left(\left(1+\frac{1}{L}\right) \boldsymbol{I}-\frac{1}{L} \boldsymbol{f}\right)^{-1}\left(\widehat{\boldsymbol{x}}_{\mathrm{red}}+\widehat{\boldsymbol{u}}_{\mathrm{red}}\right) \end{aligned}\] <p>更为直观的写法是</p> \[\begin{aligned} &amp;\widehat{\boldsymbol{x}}_{\mathrm{red}}=\boldsymbol{h}\left(\widehat{\boldsymbol{x}}_{\mathrm{red}}-\widehat{\boldsymbol{u}}_{\mathrm{red}} ; \eta\right) \\ &amp;\widehat{\boldsymbol{x}}_{\mathrm{red}}=\boldsymbol{f}\left(\widehat{\boldsymbol{x}}_{\mathrm{red}}\right)+L \widehat{\boldsymbol{u}}_{\mathrm{red}} \end{aligned}\] <p>用与 PnP 同样的方式也能证明 RED 的收敛性, 这里我们利用上式给出 RED 的另一个解释.</p> <p>将 \(h\) 代入, 从第一个方程解得</p> \[\widehat{\boldsymbol{u}}_{\mathrm{red}}=\frac{\eta}{\sigma^{2}} \boldsymbol{A}^{\intercal}\left(\boldsymbol{y}-\boldsymbol{A} \widehat{\boldsymbol{x}}_{\mathrm{red}}\right).\] <p>将之带入第二个方程得</p> \[\frac{L \eta}{\sigma^{2}} A^{\intercal}\left(A \widehat{\boldsymbol{x}}_{\mathrm{red}}-y\right)=f\left(\widehat{\boldsymbol{x}}_{\mathrm{red}}\right)-\widehat{\boldsymbol{x}}_{\mathrm{red}}\] <p>这实际上是在说, 用来拟合数据误差 (左侧) 必须和去噪的误差 (右侧) 相吻合.</p> <h2 id="red-via-fixed-point-projection-red-pro">RED via Fixed-point Projection (RED-PRO)</h2> <p>最后, 我们给出 RED 的另一种解释, 也是目前最为完善的理论, 在这一理论下, RED 与 PnP 统一在了一起, 借助比压缩映射更弱的 demicontractive 性质即可证明 PnP 与 RED 的收敛性.</p> <p>RED-PRO 的问题形式为:</p> \[\hat{\boldsymbol{x}}_{\mathrm{RED}-\mathrm{PRO}}=\underset{\boldsymbol{x} \in \mathbb{R}^{n}}{\arg \min }\; \ell(\boldsymbol{x} ; \boldsymbol{y}), \quad \text { s.t. } \boldsymbol{x} \in \operatorname{Fix}(\boldsymbol{f}).\] <p>其中 \(\operatorname{Fix}(\boldsymbol{f})\) 表示去噪算子的不动点集合. 上述问题最为直观的解释是: 在所有”好”的图像中寻找与观测最为接近的那个. 之所以这样建模, 是因为由自然图像 (即未加任何噪音) 构成的流形往往是病态且非凸的, 且难以获得有关它的任何信息. 所以, 我们退而求其次, 用 \(\operatorname{Fix}(\boldsymbol{f})\) 来近似自然图像所构成的流形. 从直观上看, 一个完美的去噪算法, 其不动点集就是自然图像所构成的流形. 然而, 主流的去噪算子都离理想状态相去甚远, 上述问题的解高度依赖于去噪算子的选择.</p> <h2 id="from-demicontractivity-to-convergence">From Demicontractivity to Convergence</h2> <h3 id="demicontractivity-及其推论">Demicontractivity 及其推论</h3> <p>为了论述的严谨性, 我们先给出 \(d\)-demicontractive 映射的定义:</p> <blockquote> <p>A mapping \(T\) is \(d\)-demicontractive (\(d \in[0,1)\)) if for any \(\boldsymbol{x} \in \mathbb{R}^{n}\) and \(\boldsymbol{z} \in \operatorname{Fix}(T)\) it holds that</p> \[\Vert T(\boldsymbol{x})-\boldsymbol{z}\Vert ^{2} \leq\Vert \boldsymbol{x}-\boldsymbol{z}\Vert ^{2}+d\Vert T(\boldsymbol{x})-\boldsymbol{x}\Vert ^{2},\] <p>or equivalently</p> \[\frac{1-d}{2}\Vert \boldsymbol{x}-T(\boldsymbol{x})\Vert ^{2} \leq\langle\boldsymbol{x}-T(\boldsymbol{x}), \boldsymbol{x}-\boldsymbol{z}\rangle.\] </blockquote> <p>该性质有如下两个重要的推论:</p> <ol> <li>假设去噪算子 \(f\) 是 \(d\)-demicontractive 的, 那么可以证明 RED-PRO 实际上是一个<strong>凸问题</strong>!</li> <li>而当 \(\boldsymbol{f}(0)=0\)时, 则有</li> </ol> \[\rho_{\mathrm{RED}}(\boldsymbol{x})=\frac{1}{2}\langle\boldsymbol{x}, \boldsymbol{x}-\boldsymbol{f}(\boldsymbol{x})\rangle=0 \text{ iff } \boldsymbol{x} \in \operatorname{Fix}(\boldsymbol{f}).\] <h3 id="red-red-pro-与-pnp-的统一">RED, RED-PRO 与 PnP 的统一</h3> <p>用以求解 RED-PRO 的混合最速下降法 (Hybrid steepest descent method) 迭代格式为:</p> \[\begin{aligned} &amp;\boldsymbol{v}_{k+1}=\boldsymbol{x}_{k}-\mu_{k} \nabla \ell\left(\boldsymbol{x}_{k} ; \boldsymbol{y}\right), \\ &amp;\boldsymbol{z}_{k+1}=f\left(\boldsymbol{v}_{k+1}\right), \\ &amp;\boldsymbol{x}_{k+1}=(1-\alpha) \boldsymbol{v}_{k+1}+\alpha \boldsymbol{z}_{k+1}. \end{aligned}\] <p>上述格式具有更为紧凑的迭代形式</p> \[\boldsymbol{x}_{k+1} = f_{\alpha}(\boldsymbol{x}_{k}-\mu_{k} \nabla \ell(\boldsymbol{x}_{k} ; \boldsymbol{y})),\text{ where } f_{\alpha} = (1-\alpha)\mathrm{Id} + \alpha f.\] <p>这种紧凑的格式与用以求解 MAP 问题的 PnP-PG (Plug-and-Play Proximal Gradient) 类似:</p> \[\boldsymbol{x}_{k+1}=f\left(\boldsymbol{x}_{k}-\mu_{k} \nabla \ell(\boldsymbol{x} ; y)\right).\] <p>而用以求解 RED 的加速邻近梯度法 (Accelerated Proximal Gradient) 格式为:</p> \[\begin{aligned} \boldsymbol{v}_{k+1} &amp;=\boldsymbol{x}_{k}-\mu_k \nabla \ell\left(\boldsymbol{x}_{k} ; \boldsymbol{y}\right), \\ \boldsymbol{z}_{k+1} &amp;=\boldsymbol{v}_{k+1}+q_{k}\left(\boldsymbol{v}_{k+1}-\boldsymbol{v}_{k}\right),\text{ (FISTA-like acceleration)} \\ \boldsymbol{x}_{k+1} &amp;=(1-\alpha) \boldsymbol{z}_{k+1}+\alpha f\left(\boldsymbol{z}_{k+1}\right). \text{ (SOR-like acceleration)} \end{aligned}\] <p>因此, 只要令 \(q_k\equiv 0\), 即舍弃类似于 FISTA 的加速步骤, 那么用以求解 RED 的加速邻近梯度法就与用以求解 RED-PRO 的混合最速下降法具有相同的迭代格式, 而当上式中的 \(\alpha\equiv 0\) 时, 即舍弃类似于 SOR 的加速步, 上述格式则与基于用 Proximal Gradient 求解 MAP 的 PnP 格式 (即用 \(f\) 替代 Proximal Gradient 中的 Proximal 步) 相同! 如此我们便用 RED 的加速邻近梯度法统一了三种模型, 并把其他两种当作 RED 的特例, 这样的等价性对收敛性的证明是大有益处的, 这意味着我们只需证明这三者中任意一个的收敛性就可以导出三种算法的收敛性.</p> <h3 id="收敛性结果">收敛性结果</h3> <p>我们直接给出收敛性的结果, 其证明较为复杂, 故略去, 请有兴趣的读者参考原论文: <a href="https://epubs.siam.org/doi/abs/10.1137/20M1337168">https://epubs.siam.org/doi/abs/10.1137/20M1337168</a>.</p> <blockquote> <p>Let \(f(\cdot)\) be a continuous \(d\)-demicontractive denoiser and \(\ell(\cdot ; \boldsymbol{y})\) be a proper convex lower semicontinuous differentiable function with \(L\)-Lipschitz gradient \(\nabla \ell(\cdot ; \boldsymbol{y})\). Assume the following:</p> \[\begin{aligned} (A1)\quad &amp;\alpha \in(0, \frac{1-d}{2}).\\ (A2)\quad &amp;\{\mu_{k}\}_{k \in \mathbb{N}} \subset[0, \infty) \text{ where } \mu_{k} \underset{k \rightarrow \infty}{\rightarrow} 0 \text{ and } \sum_{k \in \mathbb{N}} \mu_{k}=\infty. \end{aligned}\] <p>Then, the sequence \(\{\boldsymbol{x}_{k}\}_{k \in \mathbb{N}}\) generated by</p> \[\boldsymbol{x}_{k+1} = f_{\alpha}(\boldsymbol{x}_{k}-\mu_{k} \nabla \ell(\boldsymbol{x}_{k} ; \boldsymbol{y})),\text{ where } f_{\alpha} = (1-\alpha)\mathrm{Id} + \alpha f,\] <p>converges to an optimal solution of the RED-PRO problem:</p> \[\hat{\boldsymbol{x}}_{\mathrm{RED}-\mathrm{PRO}}=\underset{\boldsymbol{x} \in \mathbb{R}^{n}}{\arg \min }\; \ell(\boldsymbol{x} ; \boldsymbol{y}), \quad \text { s.t. } \boldsymbol{x} \in \operatorname{Fix}(f).\] </blockquote> <p>有了这个结果, 我们便在 Demicontractivity 的条件下证明了三种方法的收敛性!</p> <h3 id="总结">总结</h3> <p>去噪问题的建模方式多种多样, 它们都有各自的长处和缺点:</p> <ul> <li>PnP: Inspired by ADMM, Proximal gradient, while lacking objective function.</li> <li>RED: Regularization by Denoising, while many denoisers do not satisfy the assumptions.</li> <li>RED-PRO: require the denoisers to be demicontractive.</li> </ul> <p>但一旦模型建立好了, 不论采用何种算法 (基于 ADMM 的 PnP 或者基于 Proximal Gradient 的 PnP 或者基于 PDHG 的 PnP), 它们实际上都在求解同一个不动点方程:</p> \[\boldsymbol{x}_{*} = f_{\alpha}(\boldsymbol{x}_{*}-\mu_{k} \nabla \ell(\boldsymbol{x}_{*} ; \boldsymbol{y})),\text{ where } f_{\alpha} = (1-\alpha)\mathrm{Id} + \alpha f.\] <p>因此, 只要对这个不动点迭代建立收敛性结果即可.</p> <h2 id="一些可能的方向">一些可能的方向</h2> <ol> <li>对于一般的优化问题, 是否也能用 RL 来选择合适的参数?</li> <li>能否将 PnP 收敛性的条件再减弱一点?</li> <li>现有的 PnP 都是针对图像处理或者信号处理设计的, 能否将这种方法推广到一般的含 proximal 算子的算法中去?</li> </ol> <blockquote> <p>本文使用 <a href="https://zhuanlan.zhihu.com/p/106057556">https://zhuanlan.zhihu.com/p/106057556</a> 创作并发布</p> </blockquote>]]></content><author><name>Zhonglin Xie</name></author><category term="lecture notes"/><category term="L2O"/><summary type="html"><![CDATA[Plug-and-Play: 算法的推导, 利用强化学习选择参数与证明收敛性的两种框架]]></summary></entry><entry><title type="html">Concentration Inequalities</title><link href="https://zhonglinxie.github.io/blog/2021/%E9%9B%86%E4%B8%AD%E4%B8%8D%E7%AD%89%E5%BC%8F/" rel="alternate" type="text/html" title="Concentration Inequalities"/><published>2021-10-21T00:00:00+00:00</published><updated>2021-10-21T00:00:00+00:00</updated><id>https://zhonglinxie.github.io/blog/2021/%E9%9B%86%E4%B8%AD%E4%B8%8D%E7%AD%89%E5%BC%8F</id><content type="html" xml:base="https://zhonglinxie.github.io/blog/2021/%E9%9B%86%E4%B8%AD%E4%B8%8D%E7%AD%89%E5%BC%8F/"><![CDATA[<p>最近在上的两门课都频繁地用到了集中不等式, 遂作文以总结之, 主要材料来自《Foundations of Machine Learning》<d-cite key="fml2012"></d-cite>的附录 D 与《High-Dimensional Probability: An Introduction with Applications in Data Science》<d-cite key="Vershynin_2018"></d-cite>的第二章.</p> <h2 id="markovs-inequality-与-chernoff-bounding-technique">Markov’s Inequality 与 Chernoff Bounding Technique</h2> <p>最经典的集中不等式当属 Markov’s Inequality, 其证明技巧被广泛应用于其他不等式. 考虑一个非负的随机变量 \(X\), 则对每一个 \(\varepsilon&gt;0\), \(\varepsilon\mathbb{P}[X\geqslant \varepsilon] \leqslant \mathbb{E}X\), 这就是 Markov’s Inequality:</p> <blockquote> <p>设随机变量 \(X\geqslant 0\), 则 \(\forall \varepsilon &gt;0\),</p> \[\mathbb{P}[X\geqslant \varepsilon] \leqslant \frac{1}{\varepsilon} \mathbb{E}X.\] </blockquote> <p>注意到 \(e^{t\varepsilon}&gt;0,\,\mathbb{P}[X\geqslant \varepsilon]=\mathbb{P}[e^{tX}\geqslant e^{t\varepsilon}]\), 于是</p> \[\mathbb{P}[X\geqslant \varepsilon]\leqslant e^{-t\varepsilon}\mathbb{P}[e^{tX}\geqslant e^{t\varepsilon}].\] <p>我们可以通过对 \(\mathbb{P}[e^{tX}\geqslant e^{t\varepsilon}]\) 进行放缩, 得到关于 \(t\) 的函数, 再对 \(t\) 求最小值来给出 \(\mathbb{P}[X\geqslant \varepsilon]\) 的估计, 这种技巧称为 Chernoff Bounding Technique.</p> <h2 id="hoeffdings-inequality">Hoeffding’s Inequality</h2> <p>Hoeffding’s Inequality 的证明依赖于 Hoeffding’s Lemma.</p> <blockquote> <p>设 \(X\) 是在区间 \([a,b]\) 中取值且 \(\mathbb{E}X=0\) 的随机变量, 则对每一个 \(t&gt;0\), 有</p> \[\mathbb{E}\exp(tX) \leqslant \exp\left(\frac{t^2(b-a)^2}{8}\right).\] </blockquote> <p>证明: 将 \(\exp(tX)\) 视为 \(X\) 的函数, 利用凸性得到</p> \[\exp(tX)\leqslant \frac{X-a}{b-a}\exp\left(tb\right) + \frac{b-X}{b-a}\exp\left(ta\right).\] <p>由于 \(\mathbb{E}X=0\), 于是</p> \[\mathbb{E}\exp(tX) \leqslant \frac{b}{b-a}\mathbb{E}\exp\left(ta\right) - \frac{a}{b-a}\mathbb{E}\exp\left(tb\right).\] <p>定义</p> \[\varphi(t)=\log\left(\frac{b}{b-a}\exp\left(ta\right) - \frac{a}{b-a}\exp\left(tb\right)\right).\] <p>则 \(\varphi(0)=0,\,\varphi'(0)=0,\) 而</p> \[\begin{aligned} \varphi''(\xi)&amp;=\frac{ab(ae^{\xi a}-be^{\xi b})(be^{\xi a}-ae^{\xi b})-a^2b^2(e^{\xi a}-e^{\xi b})^2}{(be^{\xi a}-ae^{\xi b})^2}\\ &amp;=\frac{-ab(b-a)^2}{-2ab+a^2e^{\xi (a-b)}+b^2e^{\xi (b-a)}}\\ &amp;\leqslant \frac{(b-a)^2}{4}. \end{aligned}\] <p>利用带 Lagrange 余项的展开得, 存在 \(\xi\in(0,t)\)</p> \[\varphi(t) = \varphi(0) + \varphi'(0)t + \frac{\varphi''(\xi)}{2} t^2\leqslant \frac{t^2(b-a)^2}{8}.\] <p>故</p> \[\mathbb{E}\exp(tX) \leqslant \mathbb{E} e^{\varphi(t)} \leqslant \exp\left(\frac{t^2(b-a)^2}{8}\right).\] <blockquote> <p>假设 \(X_i\in [a_i,b_i],\,i=1,2,\ldots,m\) 是一组相互独立的随机变量, 记 \(S=\sum_{i=1}^m X_i\), 则 \(\forall \varepsilon &gt; 0\),</p> \[\begin{aligned} \mathbb{P}[S - \mathbb{E}S\geqslant \varepsilon]&amp;\leqslant \exp\left(-\frac{2\varepsilon^2}{\sum_{i=1}^{m} (b_i-a_i)^{2}}\right),\\ \mathbb{P}[S - \mathbb{E}S\leqslant -\varepsilon]&amp;\leqslant \exp\left(-\frac{2\varepsilon^2}{\sum_{i=1}^{m} (b_i-a_i)^{2}}\right). \end{aligned}\] </blockquote> <p>证明: 由 Markov’s Inequality 及 \(X_i\) 的独立性, 任取 \(t&gt;0\)</p> \[\begin{aligned} \mathbb{P}[S - \mathbb{E}S\geqslant \varepsilon]&amp;\leqslant e^{-t\varepsilon}\mathbb{E}\exp\left(t(S - \mathbb{E}S)\right)\\ &amp;= e^{-t\varepsilon} \prod_{i=1}^m \mathbb{E}\exp\left(t(X_i-\mathbb{E}X_i)\right)\\ &amp;\leqslant \exp\left(-t\varepsilon + \frac{t^2}{8}\sum_{i=1}^m(b_i-a_i)^2 \right). \end{aligned}\] <p>取 \(t=\frac{4\varepsilon}{\sum_{i=1}^m(b_i-a_i)^2}\) 得</p> \[\mathbb{P}[S - \mathbb{E}S\geqslant \varepsilon]\leqslant \exp\left(-\frac{2\varepsilon^2}{\sum_{i=1}^{m} (b_i-a_i)^{2}}\right).\] <p>对 \(-X_i\) 使用上述不等式即得</p> \[\mathbb{P}[S - \mathbb{E}S\leqslant -\varepsilon]\leqslant \exp\left(-\frac{2\varepsilon^2}{\sum_{i=1}^{m} (b_i-a_i)^{2}}\right).\] <p>相比于粗糙的 Union Bound, 即 \(\mathbb{P}(\cup A_i)\leqslant \cup \mathbb{P}A_i\), Hoeffding’s Inequality 往往能给出精确地多的估计 (不等式右端以指数平方衰减), 但 Hoeffding’s Inequality 并没有考虑随机变量 \(X_i\) 在区间 \([a_i,b_i]\) 内的分布情况, 当 \(X_i\) 的期望 \(p_i\) 已知时, 我们希望得到更精确的估计, 这就是 Multiplicative Chernoff Bounds 要做的. 为导出 Multiplicative Chernoff Bounds, 我们先证明 Sanov’s Theorem.</p> <h2 id="sanovs-theorem-chernoffhoeffding-theorem">Sanov’s Theorem (Chernoff–Hoeffding Theorem)</h2> <blockquote> <p>假设 \(X_1,\ldots,X_m\) 是相互独立且服从分布 \(\mathcal{D}\) 的随机变量, 它们在区间 \([0,1]\) 内取值, 且均值为 \(p\). 则对每一个 \(q\in [p,1]\), 有</p> \[\mathbb{P}\left[\frac{1}{m} \sum_{i=1}^{m} X_{i}\geqslant q\right] \leqslant \exp\big(-mD(q\parallel p)\big),\] <p>其中</p> \[D(q\parallel p) = q \log \frac{q}{p}+(1-q) \log \frac{1-q}{1-p}\] <p>称为 \(q\) 关于 \(p\) 的二元相对熵 (Binary Relative Entropy).</p> </blockquote> <p>证明: 对每一个 \(t &gt; 0\), 借助 Markov’s Inequality 证明中的技巧得</p> \[\begin{aligned} \mathbb{P}\left[\frac{1}{m} \sum_{i=1}^{m} X_{i}\geqslant q\right] =&amp; e^{-tmq}e^{tmq}\mathbb{P}\left[\exp\Big(t \sum_{i=1}^{m} X_{i}\Big)\geqslant e^{tmq}\right]\\ \leqslant&amp; e^{-tmq}\mathbb{E}\left[\exp\Big(t \sum_{i=1}^{m} X_{i}\Big)\right]\\ =&amp; e^{-tmq}\prod_{i=1}^{m}\mathbb{E}\left[\exp(t X_{i})\right]. \end{aligned}\] <p>将 \(\exp(t X_{i})\) 视为关于 \(X_i\) 的凸函数, 由于 \(X_i\in [0,1]\), 则</p> \[\exp(t X_{i}) \leqslant (1-X_i) \exp(t \cdot 0)+X_i\exp(t\cdot 1)=(1-X_i)+X_i\exp(t).\] <p>因此</p> \[\mathbb{E}\exp(t X_{i}) \leqslant 1-p + pe^{t}.\] <p>故 \(\forall t&gt;0\), 有</p> \[\mathbb{P}\left[\frac{1}{m} \sum_{i=1}^{m} X_{i}\geqslant q\right] \leqslant e^{-tmq}(1-p + pe^{t})^m = \big( (1-p)e^{-tq}+pe^{(1-q)t}\big)^m.\] <p>\((1-p)e^{-tq}+pe^{(1-q)t}\) 在 \(t=\log\frac{q(1-p)}{p(1-q)}\) 处取最小值. 在 \(p&lt;q\) 时, 令 \(t=\log\frac{q(1-p)}{p(1-q)}&gt;0\) 得</p> \[\begin{aligned} \mathbb{P}\left[\frac{1}{m} \sum_{i=1}^{m} X_{i}\geqslant q\right] &amp;\leqslant \left((1-p)\left(\frac{p(1-q)}{q(1-p)}\right)^q+p\left(\frac{q(1-p)}{p(1-q)}\right)^{1-q}\right)^m\\ &amp;=\left(\left(\frac{p(1-q)}{q(1-p)}\right)^q \left(1-p+p\frac{q(1-p)}{p(1-q)}\right) \right)^m\\ &amp;=\left(\left(\frac{p(1-q)}{q(1-p)}\right)^q \left(\frac{1-p}{1-q}\right) \right)^m\\ &amp;=\exp(-mD(q\parallel p)). \end{aligned}\] <p>在 \(q=p\) 时, \(D(q\parallel p)=0\), 此时欲证的概率不等式右端为 \(1\), 必然成立.</p> <p>利用 Sanov’s Theorem 可以得到比 Hoeffding’s Inequality 更好的估计, 取 \(0&lt;\varepsilon\leqslant 1-p\), 则 \(p+\varepsilon \in (p, 1]\), 于是</p> \[\mathbb{P}\left[\frac{1}{m} \sum_{i=1}^{m} X_{i}\geqslant p+\varepsilon\right] \leqslant \exp(-mD(p+\varepsilon\parallel p)).\] <p>考虑函数</p> \[f(p) = q \log \frac{q}{p}+(1-q) \log \frac{1-q}{1-p} - 2(p-q)^2,\quad p\in [0,1].\] <p>其导数为</p> \[f'(p) = -\frac{q}{p} + \frac{1-q}{1-p} - 4(p-q) = (p-q)\left(\frac{1}{p(1-p)}-4\right).\] <p>由 \(p(1-p)\leqslant 1/4\) 知 \(p=q\) 是 \(f(p)\) 的最小值点, 故 \(f(p)\geqslant f(q) = 0\), 因此</p> \[D(q\parallel p) = q \log \frac{q}{p}+(1-q) \log \frac{1-q}{1-p}\geqslant 2(p-q)^2,\] <p>该不等式称为 Pinsker’s Inequality. 取 \(q=p+\varepsilon\) 得</p> \[D(p+\varepsilon\parallel p) \geqslant 2\varepsilon^2 \quad \Rightarrow \quad \exp(-mD(p+\varepsilon\parallel p))\leqslant \exp(-2m\varepsilon^2).\] <p>这说明利用 Sanov’s Theorem 得到的估计不弱于利用 Hoeffding’s Inequality 得到的估计. 对另一方向的概率</p> \[\mathbb{P}\left[\frac{1}{m} \sum_{i=1}^{m} X_{i}\leqslant p-\varepsilon\right]\] <p>进行估计时, 仅需构造 \(Y_i = 1-X_i\), 则 \(Y_i\in [0,1],\,\mathbb{E}Y_i=1-p\), 于是</p> \[\mathbb{P}\left[\frac{1}{m} \sum_{i=1}^{m} X_{i}\leqslant p-\varepsilon\right] = \mathbb{P}\left[\frac{1}{m} \sum_{i=1}^{m} Y_{i}\geqslant 1-p+\varepsilon\right]\leqslant \exp(-mD(1-p+\varepsilon\parallel 1-p))=\exp(-mD(p-\varepsilon\parallel p)).\] <p>最后一个等式利用了二元相对熵的性质: \(D(1-p+\varepsilon\parallel 1-p) = D(p-\varepsilon\parallel p)\).</p> <h2 id="multiplicative-chernoff-bounds">Multiplicative Chernoff Bounds</h2> <blockquote> <p>假设 \(X_1,\ldots,X_m\) 是相互独立且服从分布 \(\mathcal{D}\) 的随机变量, 它们在区间 \([0,1]\) 内取值, 且均值为 \(p\). 则对每一个 \(\gamma \in [0,\frac{1}{p}-1]\), 有</p> \[\begin{aligned} \mathbb{P}\left[\frac{1}{m} \sum_{i=1}^{m} X_{i}\geqslant (1+\gamma)p\right] &amp;\leqslant \exp\big(-\frac{mp\gamma^2}{\gamma+2}\big),\\ \mathbb{P}\left[\frac{1}{m} \sum_{i=1}^{m} X_{i}\leqslant (1-\gamma)p\right] &amp;\leqslant \exp\big(-\frac{mp\gamma^2}{2}\big). \end{aligned}\] </blockquote> <p>证明: 上述结果的证明需要对二元相对熵 \(D(q\parallel p)\) 进行比 Pinsker’s Inequality 更加精确的估计, 首先要用到两个不等式:</p> \[\log(1+x) \geqslant \frac{x}{1+x/2},\quad \log(1+x)\leqslant x.\] <p>由于 \(\mathbb{P}\left[\frac{1}{m} \sum_{i=1}^{m} X_{i}\geqslant (1+\gamma)p\right]\leqslant \exp\big(-m D((1+\gamma)p\parallel p)\big)\), 仅需估计 \(D((1+\gamma)p\parallel p)\).</p> \[\begin{aligned} D((1+\gamma)p\parallel p)&amp;=(1+\gamma) p \log \frac{(1+\gamma) p}{p}+(1-(1+\gamma) p) \log \left[\frac{1-(1+\gamma) p}{1-p}\right] \\ &amp;=(1+\gamma) p \log (1+\gamma)+(1-p-\gamma p) \log \left[1-\frac{\gamma p}{1-p}\right] \\ &amp;\geqslant(1+\gamma) p \frac{\gamma}{1+\frac{\gamma}{2}}-(1-p-\gamma p) \frac{\gamma p}{1-p}\\ &amp;=\gamma^2p\left(\frac{1}{\gamma+2}+\frac{1}{1/p-1}\right)\\ &amp;\geqslant \frac{\gamma^2p}{\gamma+2}. \end{aligned}\] <p>故 \(\mathbb{P}\left[\frac{1}{m} \sum_{i=1}^{m} X_{i}\geqslant (1+\gamma)p\right]\leqslant \exp\big(-\frac{m\gamma^2p}{\gamma+2}\big)\). 再对 \(D((1-\gamma)p\parallel p)\) 进行估计, 这需要用到</p> \[(1-x) \log (1-x) \geqslant -x+\frac{x^{2}}{2},\;x\in(0,1) ,\quad (1+x)\log(1+x)\geqslant x.\] <p>由于</p> \[\begin{aligned} D((1-\gamma)p\parallel p) &amp;= (1-\gamma)p\log \frac{(1-\gamma)p}{p} + (1-p+\gamma p)\log \frac{1-p+\gamma p}{1-p}\\ &amp;\geqslant p(-\gamma + \frac{\gamma^2}{2})+(1-p)\left(1 + \frac{\gamma p}{1-p}\right)\log\left(1 + \frac{\gamma p}{1-p}\right)\\ &amp;\geqslant p(-\gamma + \frac{\gamma^2}{2}) + (1-p)\frac{\gamma p}{1-p}\\ &amp;=\frac{\gamma^2p}{2}. \end{aligned}\] <p>故 \(\mathbb{P}\left[\frac{1}{m} \sum_{i=1}^{m} X_{i}\leqslant (1-\gamma)p\right]\leqslant \exp\big(-\frac{m\gamma^2p}{2}\big)\).</p> <h2 id="azumas-inequality">Azuma’s Inequality</h2> <p>为证明 Azuma’s Inequality, 先定义鞅差序列 (Martingale Difference Sequence (MDS)):</p> <blockquote> <p>称一组随机变量序列 \(V_1,V_2,\ldots\) 为关于 \(X_1,X_2,\ldots\) 的鞅差序列, 若对每一个 \(i&gt;0\), \(V_i\) 是 \(X_1,X_2,\ldots,X_{i}\) 的函数, 并且满足</p> \[\mathbb{E}\left[V_{i+1} \mid X_{1}, \ldots, X_{i}\right]=0.\] </blockquote> <p>回顾鞅 (Martingale) 的定义:</p> <blockquote> <p>称随机变量序列 \(Y_1,Y_2,\ldots\) 为关于 \(X_1,X_2,\ldots\) 的鞅, 若</p> \[\mathbb{E}|Y_i|&lt;\infty,\quad \mathbb{E}\left[Y_{i+1} \mid X_{1}, \ldots, X_{i}\right]=Y_i.\] </blockquote> <p>鞅差序列的定义实际上是在说</p> \[\mathbb{E}\left[\sum_{k=1}^{i+1} V_{k}\mid X_{1}, \ldots, X_{i}\right]=\sum_{k=1}^{i} V_{k}.\] <p>即以 \(V_k\) 为增量的随机变量序列 \(\sum_{k=1}^{i} V_{k}\) 是鞅.</p> <p>与 Hoeffding’s Inequality 的证明类似, Azuma’s Inequality 的证明也依赖于对单变量情形的分析:</p> <blockquote> <p>假设 \(V,Z\) 是满足 \(\mathbb{E}[V\mid Z]=0\) 的随机变量, 并且对某个函数 \(f(\cdot)\) 与非负常数 \(c\geqslant 0\) 有</p> \[f(Z) \leqslant V \leqslant f(Z)+c.\] <p>则任取 \(t &gt; 0\), 有如下估计:</p> \[\mathbb{E}\left[e^{t V} \mid Z\right] \leq e^{t^{2} c^{2} / 8}.\] </blockquote> <p>证明: 将 Hoeffding’s Lemma 中的概率全部替换为关于变量 \(Z\) 的条件概率即得.</p> <p>结合鞅差序列的定义与上述推广的 Hoeffding’s Lemma, 我们可以将 Hoeffding’s Inequality 推广到更加一般的情形:</p> <blockquote> <p>设 \(V_1,V_2,\ldots\) 是关于随机变量 \(X_1,X_2,\ldots\) 的鞅差序列. 且任取 \(i&gt;0\), 存在常数 \(c_i\geqslant 0\) 与以 \(X_1,X_2,\ldots,X_{i-1}\) 为自变量的函数 \(Z_i\), 使得</p> \[Z_i\leqslant V_i \leqslant Z_i+c_i.\] <p>则任取 \(\varepsilon &gt; 0\) 与正整数 \(m\), 有下列不等式成立:</p> \[\begin{aligned}\mathbb{P}\left[\sum_{i=1}^{m} V_{i} \geqslant \varepsilon\right] \leqslant \exp \left(\frac{-2 \varepsilon^{2}}{\sum_{i=1}^{m} c_{i}^{2}}\right), \\\mathbb{P}\left[\sum_{i=1}^{m} V_{i}\leqslant-\varepsilon\right] \leqslant \exp \left(\frac{-2 \varepsilon^{2}}{\sum_{i=1}^{m} c_{i}^{2}}\right).\end{aligned}\] </blockquote> <p>证明: 记 \(S_{k}=\sum_{i=1}^{k} V_{k}\), 于是任取 \(t&gt;0\), 有</p> \[\begin{aligned} \mathbb{P}\left[S_{m} \geqslant \varepsilon\right] &amp; \leqslant e^{-t \varepsilon} \mathbb{E}\left[e^{t S_{m}}\right] \\ &amp;=e^{-t \varepsilon} \mathbb{E}\left[e^{t S_{m-1}} \mathbb{E}\left[e^{t \mathbf{V}_{m}} \mid X_{1}, \ldots, X_{m-1}\right]\right] \\ &amp; \leqslant e^{-t \varepsilon} \mathbb{E}\left[e^{t S_{m-1}}\right] e^{t^{2} c_{m}^{2} / 8} \\ &amp; \leqslant e^{-t \varepsilon} e^{t^{2} \sum_{i=1}^{m} c_{i}^{2} / 8} \\ &amp;=e^{-2 \varepsilon^{2} / \sum_{i=1}^{m} c_{i}^{2}}. \end{aligned}\] <p>其中第二步用到了重期望公式</p> \[\mathbb{E}\left[e^{t S_{m}}\right] = \mathbb{E}\left[e^{t S_{m-1}} \mathbb{E}\left[e^{t \mathbf{V}_{m}} \mid X_{1}, \ldots, X_{m-1}\right]\right],\] <p>最后一步是通过取 \(t = \frac{4\varepsilon}{\sum_{i=1}^{m} c_{i}^{2}}\) 得到的.</p> <h2 id="mcdiarmids-inequality">McDiarmid’s Inequality</h2> <blockquote> <p>设 \(X_1,X_2,\ldots,X_m\) 是一组相互独立且在 \(\mathcal{X}\) 中取值的随机变量, 函数 \(f\colon\mathcal{X}^m\to \mathbb{R}\) 满足</p> \[\left|f\left(x_{1}, \ldots, x_{i}, \ldots, x_{m}\right)-f\left(x_{1}, \ldots, x_{i}^{\prime}, \ldots x_{m}\right)\right| \leq c_{i},\quad \forall x_k\in\mathcal{X},\;x_i'\in\mathcal{X},\;k=1,2,\ldots,m,\] <p>其中 \(c_1,c_2,\ldots,c_m\) 是一组大于 \(0\) 的常数. 以 \(f(S)\) 表示 \(f(X_1,X_2,\ldots,X_m)\), 则任取 \(\varepsilon &gt; 0\), 有</p> \[\begin{aligned} \mathbb{P}[f(S)-\mathbb{E}[f(S)] \geq \varepsilon] &amp; \leq \exp \left(\frac{-2 \varepsilon^{2}}{\sum_{i=1}^{m} c_{i}^{2}}\right), \\ \mathbb{P}[f(S)-\mathbb{E}[f(S)] \leq-\varepsilon] &amp; \leq \exp \left(\frac{-2 \varepsilon^{2}}{\sum_{i=1}^{m} c_{i}^{2}}\right). \end{aligned}\] </blockquote> <p>证明: 取</p> \[V_k = \mathbb{E}\left[f(S)\mid X_1,\ldots,X_{k-1}\right]-\mathbb{E}\left[f(S)\mid X_1,\ldots,X_{k}\right],\quad k=2,3,\ldots,m.\] <p>并规定 \(V_1= f(S)-\mathbb{E}\left[f(S)\mid X_1\right]\). 可以验证这样定义的 \(V_1,V_2,\ldots,V_m\) 是关于随机变量序列 \(X_1,X_2,\ldots,X_m\) 的鞅差序列. 定义</p> \[\begin{aligned} U_{k} &amp;=\mathbb{E}\left[f(S) \mid X_{1}, \ldots, X_{k-1}\right] - \inf_{x} \mathbb{E}\left[f(S) \mid X_{1}, \ldots, X_{k-1}, x\right],\\ L_{k} &amp;=\mathbb{E}\left[f(S) \mid X_{1}, \ldots, X_{k-1}\right] - \sup_{x} \mathbb{E}\left[f(S) \mid X_{1}, \ldots, X_{k-1}, x\right]. \end{aligned}\] <p>它们分别是 \(V_k\) 的上下确界, 利用条件</p> \[\left|f\left(x_{1}, \ldots, x_{i}, \ldots, x_{m}\right)-f\left(x_{1}, \ldots, x_{i}^{\prime}, \ldots x_{m}\right)\right| \leq c_{i},\quad \forall x_k\in\mathcal{X},\;x_i'\in\mathcal{X},\;k=1,2,\ldots,m,\] <p>得 \(U_k\leqslant L_k + c_k\), 故</p> \[L_k \leqslant V_k \leqslant L_k+c_k.\] <p>再由 Sanov’s Theorem 即得</p> \[\mathbb{P}[f(S)-\mathbb{E}[f(S)] \geq \varepsilon] = \mathbb{P}\left[\sum_{i=1}^{m} V_{i} \geqslant \varepsilon\right] \leq \exp \left(\frac{-2 \varepsilon^{2}}{\sum_{i=1}^{m} c_{i}^{2}}\right).\] <p>同理可得</p> \[\mathbb{P}[f(S)-\mathbb{E}[f(S)] \leq-\varepsilon] \leq \exp \left(\frac{-2 \varepsilon^{2}}{\sum_{i=1}^{m} c_{i}^{2}}\right).\] <p>该不等式表明当自变量给函数 \(f\) 带来的改变有界时, \(f(S)\) 对均值的偏离可以被指数函数控制. Hoeffding’s Inequality 可通过取</p> \[f(S)=f(X_1,X_2,\ldots,X_m)=\frac{1}{m}\sum_{i=1}^m X_i\] <p>的 McDiarmid’s Inequality 得到.</p> <h2 id="次高斯-sub-gaussian-随机变量与-maximal-inequality">次高斯 (Sub-Gaussian) 随机变量与 Maximal Inequality</h2> <p>作为本文的结尾, 我们最后给出次高斯随机变量的定义及 Maximal Inequality. 服从高斯分布的随机变量的一个重要性质是其尾部以指数平方的概率衰减, 例如当变量 \(X\sim \mathcal{N}(0,1)\), 对每个 \(t\geqslant 0\), 有</p> \[\mathbb{P}[|X|\geqslant t]\leqslant 2e^{-t^2/2}.\] <p>这种形式的估计在实际推导中很有用, 是服从高斯分布的随机变量最重要的性质之一. 我们将这一性质推广, 并以此来定义次高斯随机变量.</p> <blockquote> <p>对随机变量 \(X\), 若存在 \(K_1&gt;0\), 使得</p> \[\mathbb{P}[|X|\geqslant t]\leqslant 2\exp\left(-t^2/K_1^2\right),\quad \forall t\geqslant 0.\] <p>则称其为次高斯随机变量.</p> </blockquote> <p>若 \(\mathbb{E}X=0\), 其还具有如下的等价定义 (此处留坑, 以后有心情再补证明):</p> <blockquote> <p>存在 \(K_5&gt;0\), 使得</p> \[\mathbb{E} \exp (\lambda X) \leq \exp \left(K_{5}^{2} \lambda^{2}\right), \quad \forall \lambda \in \mathbb{R}.\] </blockquote> <p>且在该不等式成立时, 必然有 \(\mathbb{E}X=0.\) (继续留坑)</p> <p>借助这一等价定义, 可以对由有限个次高斯随机变量构成的集合的最大值进行估计.</p> <blockquote> <p>假设 \(X_1,X_2,\ldots,X_n\) 是一组满足</p> \[\exp(tX_j)\leqslant \exp \left(\frac{r^2t^2}{2}\right),\quad j=1,2,\ldots,n\] <p>的次高斯随机变量 (不要求独立), 其中 \(r&gt;0\). 则</p> \[\mathbb{E}\left[\max _{1\leqslant j\leqslant n} X_{j}\right] \leqslant r \sqrt{2 \log n}.\] </blockquote> <p>证明: 任取 \(t&gt;0\), 利用指数函数的凸性及 Jensen’s Inequality 得</p> \[\exp\left(t \mathbb{E}\left[\max _{1\leqslant j\leqslant n} X_{j}\right]\right) \leqslant \mathbb{E}\exp\left(t \max _{1\leqslant j\leqslant n} X_{j}\right)=\mathbb{E}\left[\max _{1\leqslant j\leqslant n} \exp(tX_j)\right] \leqslant \mathbb{E}\left[\sum_{1\leqslant j\leqslant n} \exp(tX_j)\right] \leqslant \mathbb{E}\ n e^{\frac{t^{2} r^{2}}{2}}.\] <p>两边取对数并除以 \(t\) 得</p> \[\mathbb{E}\left[\max _{1\leqslant j\leqslant n} X_{j}\right] \leqslant \frac{\log n}{t}+\frac{t r^{2}}{2}.\] <p>取 \(t=\sqrt{2\log n}/r\) 即得</p> \[\mathbb{E}\left[\max _{1\leqslant j\leqslant n} X_{j}\right] \leqslant r \sqrt{2 \log n}.\] <p>该定理还有以下推论:</p> <blockquote> <p>假设 \(X_1,\ldots,X_n\) 是满足 \(X_j=\sum_{i=1}^mY_{ij}\) 的随机变量, \(Y_{ij}\) 是相互独立的随机变量, 且 \(Y_{ij}\in [-r_i,+r_i],\,r_i&gt;0,\,\mathbb{E}Y_{ij}=0\), 则</p> \[\mathbb{E}\left[\max _{1\leqslant j\leqslant n} X_{j}\right] \leqslant r \sqrt{2 \log n},\quad r=\sqrt{\sum_{i=1}^{m} r_{i}^{2}}.\] </blockquote> <p>证明: 只需证明 \(\mathbb{E}\exp\left(tX_j\right)\leqslant \exp\left(r^2t^2/2\right)\), 其中 \(r=\sqrt{\sum_{i=1}^{m} r_{i}^{2}}\). 利用 \(Y_{ij}\) 的独立性及 Hoeffding’s Inequality, 有</p> \[\mathbb{E}\left[e^{t X_{j}}\right]=\mathbb{E}\left[\prod_{i=1}^{m} e^{t Y_{i j}}\right]=\prod_{i=1}^{m} \mathbb{E}\left[e^{t Y_{i j}}\right] \leqslant \prod_{i=1}^{m} e^{\frac{t^{2} r_{j}^{2}}{2}}=e^{\frac{t^{2} r^{2}}{2}}.\] <p>再由 Maximal Inequality 即得</p> \[\mathbb{E}\left[\max _{1\leqslant j\leqslant n} X_{j}\right] \leqslant r \sqrt{2 \log n},\quad r=\sqrt{\sum_{i=1}^{m} r_{i}^{2}}.\]]]></content><author><name>Zhonglin Xie</name></author><category term="math"/><summary type="html"><![CDATA[集中不等式概要]]></summary></entry><entry><title type="html">Poisson Kernel on the Upper Half-Space Integrates to 1 on the Boundary</title><link href="https://zhonglinxie.github.io/blog/2021/n%E7%BB%B4%E7%A9%BA%E9%97%B4%E4%B8%8A%E5%8D%8A%E7%A9%BA%E9%97%B4%E6%B3%8A%E6%9D%BE%E6%A0%B8-Poisson-Kernel-%E5%9C%A8%E8%BE%B9%E7%95%8C%E7%A7%AF%E5%88%86%E4%B8%BA1%E7%9A%84%E4%B8%80%E4%B8%AA%E8%AF%81%E6%98%8E/" rel="alternate" type="text/html" title="Poisson Kernel on the Upper Half-Space Integrates to 1 on the Boundary"/><published>2021-08-16T03:12:00+00:00</published><updated>2021-08-16T03:12:00+00:00</updated><id>https://zhonglinxie.github.io/blog/2021/n%E7%BB%B4%E7%A9%BA%E9%97%B4%E4%B8%8A%E5%8D%8A%E7%A9%BA%E9%97%B4%E6%B3%8A%E6%9D%BE%E6%A0%B8%20Poisson%20Kernel%20%E5%9C%A8%E8%BE%B9%E7%95%8C%E7%A7%AF%E5%88%86%E4%B8%BA1%E7%9A%84%E4%B8%80%E4%B8%AA%E8%AF%81%E6%98%8E</id><content type="html" xml:base="https://zhonglinxie.github.io/blog/2021/n%E7%BB%B4%E7%A9%BA%E9%97%B4%E4%B8%8A%E5%8D%8A%E7%A9%BA%E9%97%B4%E6%B3%8A%E6%9D%BE%E6%A0%B8-Poisson-Kernel-%E5%9C%A8%E8%BE%B9%E7%95%8C%E7%A7%AF%E5%88%86%E4%B8%BA1%E7%9A%84%E4%B8%80%E4%B8%AA%E8%AF%81%E6%98%8E/"><![CDATA[<p>在 Evans PDE 的 P38 关于 Laplace 方程解的推导中需用到如下积分:</p> \[\int_{\partial \mathbb{R}^{n}_{+}} K(x,y)\, \mathrm{d}y = 1,\] <p>其中</p> \[K(x, y):=\frac{2 x_{n}}{n \alpha(n)} \frac{1}{|x-y|^{n}} \quad(x \in \mathbb{R}_{+}^{n}, y \in \partial \mathbb{R}_{+}^{n})\] <p>为 \(n\) 维空间上的泊松核 (Poisson Kernel), \(\mathbb{R}^{n}_{+}=\{(y_1,y_2,\cdots,y_n)\mid y_n &gt; 0\}\) 表示 \(n\) 维空间的上半空间, \(\partial \mathbb{R}^{n}_{+}=\mathbb{R}^{n-1}\) 为 \(\mathbb{R}^{n}_{+}\) 的边界,</p> \[\alpha(n)=\frac{\pi^{n/2}}{\Gamma(\frac{n}{2}+1)}\] <p>为 \(\mathbb{R}^{n}\) 中单位球的体积. 利用 \(\partial \mathbb{R}^{n}_{+}\) 与 \(\mathbb{R}^{n-1}\) 的等价性可得</p> \[\begin{aligned} \int_{\partial \mathbb{R}_+^n} K(x,y) \,\mathrm{d}y &amp;= \int_{\mathbb{R}^{n-1}} K(x,y) \,\mathrm{d}y \\&amp;= \int_{\mathbb{R}^{n-1}} \frac{2x_n}{n \alpha(n)} \frac{1}{|x-y|^n} \,\mathrm{d}y \\ &amp;= \frac{2x_n}{n \alpha(n)} \int_{\mathbb{R}^{n-1}}\frac{1}{(x_{n}^2+y_{1}^2+...+y_{n-1}^2)^{\frac{n}{2}}} \,\mathrm{d}y \\&amp;= \frac{2x_n}{n \alpha(n)} \int_{\mathbb{R}^{n-1}}\frac{1}{(x_{n}^2+|y|^2)^{\frac{n}{2}}} \,\mathrm{d}y\\ &amp;= \frac{2}{n \alpha(n)x_n^{n-1}} \int_{\mathbb{R}^{n-1}}\frac{1}{(1+|y/x_n|^2)^{\frac{n}{2}}} \,\mathrm{d}y \end{aligned}\] <p>做变量代换 \(z=y/x_n\) 得</p> \[\int_{\partial \mathbb{R}_+^n} K(x,y) \,\mathrm{d}y = \frac{2}{n \alpha(n)} \int_{\mathbb{R}^{n-1}}\frac{1}{(1+|z|^2)^{\frac{n}{2}}} \,\mathrm{d}z.\] <p>借助 \(n-1\) 维空间中的极坐标变换, 上式可以写为</p> \[\begin{aligned} \frac{2}{n \alpha(n)} \int_{\mathbb{R}^{n-1}}\frac{1}{(1+|z|^2)^{\frac{n}{2}}} \,\mathrm{d}z &amp;= \frac{2}{n \alpha(n)} \int_{0}^{\infty}\int_{\partial B(0,r)}\frac{1}{(1+r^2)^{\frac{n}{2}}}\,\mathrm{d}S \,\mathrm{d}r \\ &amp;= \frac{2(n-1)\alpha(n-1)}{n \alpha(n)} \int_{0}^{\infty}\frac{r^{n-2}}{(1+r^2)^{\frac{n}{2}}} \,\mathrm{d}r, \end{aligned}\] <p>其中 \(B(0,r)=\{x\in \mathbb{R}^{n-1}\mid \|x\|^2&lt;r\}\) 是 \(n-1\) 维空间中以原点为球心, \(r\) 为半径的开球. 第二个等号用到了 \(n-1\) 维空间中球的表面积公式</p> \[\int_{\partial B(0,r)} 1 \,\mathrm{d}S = (n-1)\alpha(n-1)r^{n-2}.\] <p>记 \(S(n)=n\alpha(n)\), 它实际上等于 \(n\) 维空间中单位球的表面积, 利用 \(\Gamma\) 函数的性质</p> \[\begin{aligned} \Gamma(z+1) &amp;=\int_{0}^{\infty} x^{z} e^{-x} \,\mathrm{d} x \\ &amp;=\left[-x^{z} e^{-x}\right]_{0}^{\infty}+\int_{0}^{\infty} z x^{z-1} e^{-x} \,\mathrm{d} x \\ &amp;=\lim_{x \rightarrow \infty}\left(-x^{z} e^{-x}\right)-\left(-0^{z} e^{-0}\right)+z \int_{0}^{\infty} x^{z-1} e^{-x} \,\mathrm{d} x\\ &amp;=z\Gamma(z) \end{aligned}\] <p>知 \(\Gamma(\frac{n}{2}+1)=\frac{n}{2}\Gamma(\frac{n}{2})\), 于是</p> \[S(n)=n\alpha(n)=\frac{n\pi^{n/2}}{\Gamma(\frac{n}{2}+1)}=\frac{2\pi^{n/2}}{\Gamma(\frac{n}{2})}.\] <p>最终我们得到</p> \[\begin{aligned} \frac{2(n-1)\alpha(n-1)}{n \alpha(n)} \int_{0}^{\infty}\frac{r^{n-2}}{(1+r^2)^{\frac{n}{2}}} \,\mathrm{d}r = \frac{2S(n-1)}{S(n)} \int_{0}^{\infty}\frac{r^{n-2}}{(1+r^2)^{\frac{n}{2}}} \,\mathrm{d}r \\ = \frac{2\Gamma(\frac{n}{2})}{\Gamma(\frac{n-1}{2})\sqrt{\pi}}\int_{0}^{\infty}\frac{r^{n-2}}{(1+r^2)^{\frac{n}{2}}}\,\mathrm{d}r. \end{aligned}\] <blockquote> <p>于是只需验证</p> \[\int_{0}^{\infty}\frac{r^{n-2}}{(1+r^{2})^{\frac{n}{2}}}\,\mathrm{d}r=\frac{\Gamma(\frac{n-1}{2})\sqrt{\pi}}{2\Gamma(\frac{n}{2})}.\] <p>我们对 \(n\) 归纳, 当 \(n=2\) 时</p> \[\begin{aligned} \int_{0}^{\infty}\frac{1}{1+r^2}\,\mathrm{d}r&amp;=\int_{0}^{\frac{\pi}{2}}\frac{1}{\cos^{2}r(1+\tan^{2}r)}\,\mathrm{d}r\\ &amp;=\int_{0}^{\frac{\pi}{2}}\frac{\cos^2r}{\cos^2r}\,\mathrm{d}r=\frac{\pi}{2}. \end{aligned}\] <p>\(n\geq 3\)时, 由分部积分可知</p> \[\begin{aligned} \int_{0}^{\infty}\frac{r^{n-2}}{(1+r^{2})^{\frac{n}{2}}}\,\mathrm{d}r &amp;=-\frac{1}{n-2}\int_{0}^{\infty}r^{n-3}\,\mathrm{d}\frac{1}{(1+r^2)^{\frac{n-2}{2}}}\\ &amp;=\underbrace{\left[-\frac{1}{n-2}\frac{1}{(1+r^2)^{\frac{n-2}{2}}}r^{n-3}\right]_{0}^{\infty}}_{=0}+\frac{n-3}{n-2}\int_{0}^{\infty}\frac{r^{n-4}}{(1+r^{2})^{\frac{n-2}{2}}}\,\mathrm{d}r. \end{aligned}\] <p>由归纳法的假设</p> \[\begin{aligned} \int_{0}^{\infty}\frac{r^{n-4}}{(1+r^{2})^{\frac{n-2}{2}}}\,\mathrm{d}r=\frac{\Gamma(\frac{n-3}{2})\sqrt{\pi}}{2\Gamma(\frac{n-2}{2})} \end{aligned}\] <p>及 \(\Gamma\) 函数的性质 \(z\Gamma(z)=\Gamma(z+1)\) 得</p> \[\begin{aligned} \int_{0}^{\infty}\frac{r^{n-2}}{(1+r^{2})^{\frac{n}{2}}}\,\mathrm{d}r&amp;=\frac{n-3}{n-2}\int_{0}^{\infty}\frac{r^{n-4}}{(1+r^{2})^{\frac{n-2}{2}}}\,\mathrm{d}r\\ &amp;=\frac{\frac{n-3}{2}}{\frac{n-2}{2}}\frac{\Gamma(\frac{n-3}{2})\sqrt{\pi}}{2\Gamma(\frac{n-2}{2})}\\ &amp;=\frac{\Gamma(\frac{n-1}{2})\sqrt{\pi}}{2\Gamma(\frac{n}{2})}, \end{aligned}\] <p>故结论成立.</p> </blockquote>]]></content><author><name></name></author><category term="math"/><summary type="html"><![CDATA[n维空间上半空间泊松核 (Poisson Kernel) 在边界积分为1的一个证明]]></summary></entry></feed>